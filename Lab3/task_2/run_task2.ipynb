{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from utils import print_ptree\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import copy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class CC() :\n",
    "    '''\n",
    "        Classifier Chain\n",
    "    '''\n",
    "\n",
    "    h = None\n",
    "    L = -1\n",
    "\n",
    "    def __init__(self, h=LogisticRegression()):\n",
    "        ''' \n",
    "        Setup.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h : a sklearn model\n",
    "            The instantiated base classifier\n",
    "\n",
    "        '''\n",
    "        self.base_classifier = h\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        ''' \n",
    "        Train the chain.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : input matrix (N * D array)\n",
    "        Y : label matrix (N * L array)\n",
    "\n",
    "        '''\n",
    "        N, self.L = Y.shape\n",
    "        L         = self.L\n",
    "        N, D      = X.shape\n",
    "\n",
    "        # Copy the base model for each label ...\n",
    "        self.h = [ copy.deepcopy(self.base_classifier) for j in range(L)]\n",
    "        XY = zeros((N, D + L-1))\n",
    "        XY[:,0:D] = X\n",
    "        XY[:,D:] = Y[:,0:L-1]\n",
    "        # ... and train each model.\n",
    "        for j in range(self.L):\n",
    "            self.h[j].fit(XY[:,0:D+j], Y[:,j])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def explore_paths(self, x, epsilon=0.5):\n",
    "        '''\n",
    "            epsilon-Greedy exploration of the probability tree.\n",
    "\n",
    "            Carry out an exploration of the probability tree given instance x,\n",
    "            using the epsilon-greedy strategy.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "                x       : A D-dimensional array contains values for the D input features.\n",
    "                epsilon : float value of epsilon considered in the search\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "                branches : a list of branches involved in your search, where \n",
    "                           a branch is a tuple (parent,child,branch_score,path_score) where\n",
    "                            - parent : an integer array to identify the path to this node\n",
    "                            - child  : an integer array to identify the path to this node\n",
    "                            - branch_score : the score by taking this branch\n",
    "                            - path_score   : the score obtained so far along the path relevant to this branch\n",
    "                y        : the best path (of those explored) to a goal node\n",
    "                p        : the score/payoff associated with this path\n",
    "        '''\n",
    "\n",
    "        ###############################################\n",
    "        #       This function is implemented as UCS \n",
    "        #       ε-approximate search and works for \n",
    "        #       any espilon\n",
    "        ###############################################\n",
    "\n",
    "        branches       = []    # to store the branches we go down\n",
    "        priority_queue = []    # priority-queue to implement UCS ε-approximate search\n",
    "        final_branches = []    # to store the final branches (when j = self.L)\n",
    "        y  = zeros(self.L)     # an array to store labels (the best path)\n",
    "        p  = 1.                # path score so far\n",
    "        j  = -1                # current label index\n",
    "\n",
    "        priority_queue.append((p,j,y)) # Initialize the priority queue\n",
    "\n",
    "        while priority_queue:\n",
    "            p,j,y = priority_queue.pop() # Pop next neihboor in the tree\n",
    "            j+=1\n",
    "\n",
    "            if j<self.L: # Stop condition\n",
    "                \n",
    "                if j>0:\n",
    "                    xy = append(x, y[0:j]).reshape(1,-1) # Add previous predictions to the testing set\n",
    "                else:\n",
    "                    xy = x.reshape(1,-1) # Make x into a 2*D array\n",
    "\n",
    "                P_j = self.h[j].predict_proba(xy)[0] # (N.B. [0], because it is the first and only row)\n",
    "                for k, proba in enumerate(P_j): # Go trough labels and their probas\n",
    "                    if proba > epsilon: # \n",
    "                        y_c = copy.deepcopy(y) # Make a deep copy of the paths to save them in branches\n",
    "                        y_c[j] = k # Epsilon-greedy strategy\n",
    "                        p_new = p*proba\n",
    "                        branch = (y_c[0:j].astype(int),y_c[0:j+1].astype(int),proba,p_new)\n",
    "                        branches.append(branch)\n",
    "                        priority_queue.append((p_new,j,y_c))\n",
    "                        priority_queue.sort() # Sort the list as a priority queue\n",
    "\n",
    "                        if j == self.L-1:\n",
    "                            final_branches.append(branch) # Keep complete branches \n",
    "        \n",
    "        _, y, _, p = sorted(final_branches, key=lambda tup: tup[3], reverse=True)[0] # Get the best path according to its costs among the final branches\n",
    "\n",
    "        return branches,y,p\n",
    "\n",
    "\n",
    "    def predict(self, X, epsilon=0.5):\n",
    "        ''' \n",
    "        Predict.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : input matrix (N * D array)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "\n",
    "        A binary matrix (N * L array) of predictions.\n",
    "\n",
    "        '''\n",
    "\n",
    "        N,D = X.shape\n",
    "        Yp = zeros((N,self.L))\n",
    "\n",
    "        for n in range(N):\n",
    "            x = X[n]\n",
    "            paths,yp,w_max = self.explore_paths(x, epsilon)\n",
    "            Yp[n] = yp\n",
    "\n",
    "        return Yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "random.seed(0)    # <--- May be changed for grading\n",
    "eps = .0         # <--- May be changed for grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset, shuffle and split it.\n",
    "L = 6\n",
    "XY = genfromtxt('Music.csv', skip_header=1, delimiter=\",\")\n",
    "random.shuffle(XY)\n",
    "N,DL = XY.shape\n",
    "X = XY[:,L:DL]\n",
    "Y = XY[:,0:L]\n",
    "N_train = N-10\n",
    "X_test = X[N_train:]\n",
    "Y_test = Y[N_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CC at 0x10ca25240>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train a classifier chain \n",
    "# (except for 10 examples -- our test set)\n",
    "cc = CC()\n",
    "cc.fit(X[0:N_train], Y[0:N_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Y-pred:\n",
      "[[0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 0. 1. 1. 1. 0.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 1. 0. 0. 0.]]\n",
      "\n",
      "Results:\n",
      "Loss per test instance:  [2 1 1 2 3 0 0 2 1 0] ; 0/1 loss:  0.7\n"
     ]
    }
   ],
   "source": [
    "# Obtain predictions, and all paths explored to obtain each prediction\n",
    "Y_pred = cc.predict(X_test,epsilon=eps)\n",
    "print(\"\\nY-pred:\")\n",
    "print(Y_pred)\n",
    "\n",
    "E = (Y_pred != Y_test) * 1\n",
    "print(\"\\nResults:\")\n",
    "print(\"Loss per test instance: \", E.sum(axis=1), \"; 0/1 loss: \", sum(E.sum(axis=1)>0)/E.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = linspace(0,.5,1001)\n",
    "\n",
    "losses = []\n",
    "for eps in x:\n",
    "    Y_pred = cc.predict(X_test,epsilon=eps)\n",
    "    E = (Y_pred != Y_test) * 1\n",
    "    losses.append(sum(E.sum(axis=1)>0)/E.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFAlJREFUeJzt3X2MXFd9xvHvEzsmFAi42ELBL1lTjEygEYbFFGigLQQsKtm00HZd2pKKyqUkaZWC1FTQNDJCqCCavuCWmhZRQIpJrRYtwtQYkgghOeB1cZLalp1NeMmGFhaoQSECy+bXP+ZuMplsPHd3Z3fu757nI6009865u+fkOM+ee849O4oIzMysDBcMuwJmZrZ0HPpmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVx6JuZFcShb2ZWEIe+mVlBlg+7Ar1WrVoVIyMjw66GmVkqR44c+W5ErO5XrnGhPzIywsTExLCrYWaWiqRv1Cnn6R0zs4I49M3MCuLQNzMriEPfzKwgDn0zs4LUCn1JWyWdlDQp6fpZ3l8v6TZJX5V0l6TXdb3359V1JyW9dpCVNzOzuen7yKakZcBu4EpgCjgsaTwijncVexdwS0T8o6TLgP3ASPV6DHge8Ezg85KeExHnBt0QMzPrr85z+luAyYi4D0DSXmA70B36AVxcvX4q8K3q9XZgb0T8BPiapMnq+x0aQN3NinXw+Le5e+r0sKthlS0bns4vblw17GrUUif01wD3dx1PAS/pKXMj8DlJ1wJPAl7dde0dPdeu6f0BknYCOwHWr19fp95mRfuLT/03//vDHyMNuyYWAc+95Dt89k+uGHZVahnUjtwdwEcj4gOSXgp8XNLz614cEXuAPQCjo6P+pHazPs5FsGPLet776z8/7KoU760fP8LXvvujYVejtjqh/wCwrut4bXWu21uArQARcUjSRcCqmtea2RyFh0aNEuTpkDpP7xwGNkraIGkFnYXZ8Z4y3wReBSDpucBFwHRVbkzSEyRtADYCXxlU5c3MbG76jvQj4qyka4ADwDLgIxFxTNIuYCIixoG3Ax+WdB2dRd2rIiKAY5JuobPoexa42k/umA2G5/ObIVs/1JrTj4j9dB7D7D53Q9fr48DLH+fa9wDvWUAdzewx8kwnlCDTdJt35JqZFcShb5ZQBCSbVWgtKdd9l0PfzKwgDn2zpLItILaVkt1zOfTNEso0nVCCSLSS69A3MyuIQ98soYhIN63QWl7INTOzpnLomyXlhdxmyNYNDn2zhDJNJxQhUYc49M3MCuLQN0vIO3KbQ1Kmgb5D38ysJA59s6TkldxGyNYLDn2zhDLtAC1Bpv5w6JuZFcShb5ZQnnFl+/lPK5uZWWM59M2S8jpuM2TrBoe+WUaZ5hMKkGgd16FvZlYSh75ZUv7Tys2Qbb+EQ98soUSzCUWIRD3i0DdLKtkAs7WydYND3yyhTDtAS5CpOxz6ZmYFceibJZVtWqG1knWEQ98soUSzCUXw9I6ZLTov5DZDtkdnHfpmCWUaWVqz1Ap9SVslnZQ0Ken6Wd6/SdLR6uuUpNNd771P0jFJJyT9nbLtZDAza5Hl/QpIWgbsBq4EpoDDksYj4vhMmYi4rqv8tcDm6vXLgJcDl1dvfwl4JXD7gOpvViyPn5ohWzfUGelvASYj4r6IOAPsBbafp/wO4ObqdQAXASuAJwAXAt+ef3XNDHLtAC1Bpn0TdUJ/DXB/1/FUde4xJF0KbABuBYiIQ8BtwP9UXwci4sRCKmxmHckGmK2VrR8GvZA7BuyLiHMAkp4NPBdYS+cXxa9IuqL3Ikk7JU1Impienh5wlczaJ9HAsgiZuqNO6D8ArOs6Xludm80Yj0ztAPwacEdEPBgRDwKfBV7ae1FE7ImI0YgYXb16db2am5nZnNUJ/cPARkkbJK2gE+zjvYUkbQJWAoe6Tn8TeKWk5ZIupLOI6+kds0HINq/QUq1byI2Is8A1wAE6gX1LRByTtEvStq6iY8DeePSKxj7gXuBu4E7gzoj49MBqb1aoTNMJJcg03db3kU2AiNgP7O85d0PP8Y2zXHcO+MMF1M/MHke2naBtla0fvCPXLKNEI8sSZHqE1qFvZlYQh75ZUtkWENsqWz849M0SyjSdUIJMC7kOfbOkkg0wW8sjfTNbdJlGliXI1B0OfTOzgjj0zZLKNq3QXrk6wqFvllCm6YQSZJpuc+ibmRXEoW+WUESk2/7fVp1ptjxDfYe+mVlBHPpmSXkhtxmydYND3yyhPJMJZfBCrpmZNZJD3yyhiHzTCm0l5brzcuibmRXEoW+WlVdyGyHbo7MOfTOzBYpEK7kOfTOzgjj0zZKZGVXmmlRoLy/kmplZYzn0zZLyOm4zZOsGh75ZMonWDIuRqU8c+mZmBXHomyUzM6jM9nx4W0nyI5tmZtZMDn2zpLyQa/Ph0DdLJtNUQiky9YhD38ysIA59s2QeWci1JpBINdSvFfqStko6KWlS0vWzvH+TpKPV1ylJp7veWy/pc5JOSDouaWRw1Tczs7lY3q+ApGXAbuBKYAo4LGk8Io7PlImI67rKXwts7voWHwPeExEHJT0Z+OmgKm9WMi/kNkO2R2frjPS3AJMRcV9EnAH2AtvPU34HcDOApMuA5RFxECAiHoyIhxZYZ7OieR23eTJ1SZ3QXwPc33U8VZ17DEmXAhuAW6tTzwFOS/p3SV+V9P7qzqH3up2SJiRNTE9Pz60FZmZW26AXcseAfRFxrjpeDlwBvAN4MfAs4KreiyJiT0SMRsTo6tWrB1wls3aS53caIVs31An9B4B1Xcdrq3OzGaOa2qlMAUerqaGzwKeAF86nombWEakmE8qQae9EndA/DGyUtEHSCjrBPt5bSNImYCVwqOfap0maGb7/CnC891ozs6ySDfT7h341Qr8GOACcAG6JiGOSdkna1lV0DNgbXb/yqmmedwBfkHQ3nf8+Hx5kA8xKk2hQWYxMXdL3kU2AiNgP7O85d0PP8Y2Pc+1B4PJ51s/MzAbIO3LNksq2gNhW2frBoW9mtkCZptwc+mZJZdsJ2lbZHp116Jslk2lUWYpMj9E69M3MCuLQN0sq2axCa2XrBoe+WTKZphJKkWnKzaFvllS2EWZrJesIh75ZMplGlaXI1CUOfTOzgjj0zZLyQm4zZNsv4dA3SybTVEIxEnWKQ98sqWwjzLbKdsfl0DdLJtMHdpQi02O0Dn0zs4I49M2Syjat0FbZusGhb5ZMnomEcmSacXPom5ktQLY7Loe+WTKZRpWlyNQlDn0zs4I49M2SyvaJTW2Vbb+EQ98sm0xzCYXItHfCoW9mVhCHvlkyM7s/c00qtJeU6+bLoW9mVhCHvllSXsdthmzd4NA3SybRmmExMvWJQ9/MrCAOfbNkZgaV2aYVWivZPJtD38ysILVCX9JWSSclTUq6fpb3b5J0tPo6Jel0z/sXS5qS9MFBVdysdN6R2wzZemF5vwKSlgG7gSuBKeCwpPGIOD5TJiKu6yp/LbC559u8G/jiQGpsVrhMuz9LEhEpfhHXGelvASYj4r6IOAPsBbafp/wO4OaZA0kvAp4BfG4hFTUzs4WrE/prgPu7jqeqc48h6VJgA3BrdXwB8AHgHQurppnNeHght/mDyiLM9EOWG7BBL+SOAfsi4lx1/DZgf0RMne8iSTslTUiamJ6eHnCVzMxsRt85feABYF3X8drq3GzGgKu7jl8KXCHpbcCTgRWSHoyIRy0GR8QeYA/A6Ohokt+XZsPlgX4zZPvTynVC/zCwUdIGOmE/Bvx2byFJm4CVwKGZcxHxpq73rwJGewPfzOYmyzRCabJ0S9/pnYg4C1wDHABOALdExDFJuyRt6yo6BuwNP1pgZtZYdUb6RMR+YH/PuRt6jm/s8z0+Cnx0TrUzs8eY+dPKXslthkcWcoMMk27ekWtmVhCHvllSzR9TliFbPzj0zbLxqlkjZekWh76ZWUEc+mZJeR23GbL1g0PfLJks0wilyfKwukPfLKlsO0HbKsNf1uzm0DdLJsuIsjSR5B7MoW9mVhCHvllSyWYVrCEc+mbJZJlGKE2WaTeHvllSHug3Q7Y7Loe+WTJZRpTWTA59M7OCOPTNkso2rdBW2fZLOPTNkvHsTjNlmXZz6JsllW2E2VbZ7rgc+mbJ+BNJmynLo7QOfTOzgjj0zbJKNq3QVtm6waFvloxnd5opS7849M2SyjbCbCsv5JqZFSjJQN+hb2ZWEoe+WVLZPrGprbLtl3DomyWTZcGwNFn2Tzj0zZLKNb5sr2w3XA59s2Sy7PwsTZZeceibmRXEoW+WVLZpBWsGh75ZMknWC4uTpV9qhb6krZJOSpqUdP0s798k6Wj1dUrS6er8CyQdknRM0l2SfmvQDTArlUf6zZDt0dnl/QpIWgbsBq4EpoDDksYj4vhMmYi4rqv8tcDm6vAh4Pci4h5JzwSOSDoQEacH2QizkiQZUJYnScfUGelvASYj4r6IOAPsBbafp/wO4GaAiDgVEfdUr78FfAdYvbAqm5nZfNUJ/TXA/V3HU9W5x5B0KbABuHWW97YAK4B7Z3lvp6QJSRPT09N16m1WvGw7QdsqWy8MeiF3DNgXEee6T0q6BPg48PsR8dPeiyJiT0SMRsTo6tW+ETA7nyw7P0uTZf9EndB/AFjXdby2OjebMaqpnRmSLgY+A7wzIu6YTyXNzGww6oT+YWCjpA2SVtAJ9vHeQpI2ASuBQ13nVgD/AXwsIvYNpspmZZsZTyZ7aKS1Zvohyw1Y39CPiLPANcAB4ARwS0Qck7RL0rauomPA3nj0vedvAq8Arup6pPMFA6y/mZnNQd9HNgEiYj+wv+fcDT3HN85y3SeATyygfmZmjZbthss7cs2SyTKNUJos3eLQNzMriEPfLJ3OmDLb9v+2mumHLI/SOvTNzAri0DdLyuP8Zsh2w+XQN0smySxCcbJ0i0PfzKwgDn2zZLwjt1lmuiHLHZhD38ysIA59s6T8p5UbItktl0PfLJks0wiladOfVjYzs5Zw6JslEw/vyB1yRQzo2i+RY6Dv0DczK4lD3ywpD/SbIdsdl0PfLBkv5DZTlm5x6JuZFcShb5ZUtmmFtsq2X8Khb5aMp3eaKUu/OPTN0so1wmyrbHdcDn2zZLLs/CxNln5x6JuZFcShb5ZUtmmFtsrWDQ59s2SyLBiWJku/OPTNkso2wmyrbHdcDn0zswFIMtB36JuZlcShb5aUss0rtJR35JrZosqyYFiaSNIxDn2zpHKNL1ssWUfUCn1JWyWdlDQp6fpZ3r9J0tHq65Sk013vvVnSPdXXmwdZebMSZdn5WZokA32W9ysgaRmwG7gSmAIOSxqPiOMzZSLiuq7y1wKbq9c/C/wlMEpncftIde3/DbQVZmZWS52R/hZgMiLui4gzwF5g+3nK7wBurl6/FjgYEd+vgv4gsHUhFTazDq/jNkO2bug70gfWAPd3HU8BL5mtoKRLgQ3Aree5ds3cq9nf6YfO8BsfOrQY39qsUX589tywq2Cz+N1/+TIXLlvYMummSy7m73dsHlCNZlcn9OdiDNgXEXP6VylpJ7ATYP369fP6wRdcIDY+48nzutYsmy0jT2fz+pXDroYBL3v2Kl7/gmdy5txPF/y91q184gBqdH51Qv8BYF3X8drq3GzGgKt7rv2lnmtv770oIvYAewBGR0fntRxy8UUX8g9vetF8LjUzm7c1T3sifzO2uKPzQapzL3IY2Chpg6QVdIJ9vLeQpE3ASqB7juUA8BpJKyWtBF5TnTMzsyHoO9KPiLOSrqET1suAj0TEMUm7gImImPkFMAbsja4dChHxfUnvpvOLA2BXRHx/sE0wM7O61LRdZKOjozExMTHsapiZpSLpSESM9ivnHblmZgVx6JuZFcShb2ZWEIe+mVlBHPpmZgVp3NM7kqaBbyzgW6wCvjug6mRRWptLay+4zaVYSJsvjYjV/Qo1LvQXStJEnceW2qS0NpfWXnCbS7EUbfb0jplZQRz6ZmYFaWPo7xl2BYagtDaX1l5wm0ux6G1u3Zy+mZk9vjaO9M3M7HGkDP0aH9T+BEmfrN7/sqSRpa/lYNVo8ysk/Zeks5LeOIw6DlqNNv+ppOOS7pL0heqT21Kr0ea3Srpb0lFJX5J02TDqOUj92txV7g2SQlL6J3pq9PNVkqarfj4q6Q8G9sMjItUXnT/vfC/wLGAFcCdwWU+ZtwEfql6PAZ8cdr2XoM0jwOXAx4A3DrvOS9TmXwZ+pnr9R4X088Vdr7cB/znsei92m6tyTwG+CNwBjA673kvQz1cBH1yMn59xpF/ng9q3A/9avd4HvEpK/THSfdscEV+PiLuAhX9mWzPUafNtEfFQdXgHnU9my6xOm3/YdfgkIPuiXJ3/nwHeDfwV8OOlrNwiqdvmRZEx9Ot82PrDZSLiLPAD4OlLUrvFsWQfMN8gc23zW4DPLmqNFl+tNku6WtK9wPuAP16iui2Wvm2W9EJgXUR8Zikrtojq/tt+QzV1uU/Sulnen5eMoW/2KJJ+BxgF3j/suiyFiNgdET8H/BnwrmHXZzFJugD4a+Dtw67LEvs0MBIRlwMHeWTmYsEyhn6dD2p/uIyk5cBTge8tSe0Wx1w+nL4tarVZ0quBdwLbIuInS1S3xTLXft4LvH5Ra7T4+rX5KcDzgdslfR34BWA8+WJu336OiO91/Xv+Z+BFg/rhGUO/zge1jwNvrl6/Ebg1qtWRpGp9OH3L9G2zpM3AP9EJ/O8MoY6DVqfNG7sOfxW4ZwnrtxjO2+aI+EFErIqIkYgYobN2sy0iMn+map1+vqTrcBtwYmA/fdgr2fNc/X4dcIrOCvg7q3O76PxjALgI+DdgEvgK8Kxh13kJ2vxiOnODP6JzV3Ns2HVegjZ/Hvg2cLT6Gh92nZegzX8LHKvaexvwvGHXebHb3FP2dpI/vVOzn99b9fOdVT9vGtTP9o5cM7OCZJzeMTOzeXLom5kVxKFvZlYQh76ZWUEc+mZmBXHom5kVxKFvZlYQh76ZWUH+Hxpd/5x2QaR2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Branches:\n",
      "  From []           to [0]            with cost 0.61 (path-cost so far: 0.61)\n",
      "  From []           to [1]            with cost 0.39 (path-cost so far: 0.39)\n",
      "  From [0]          to [0 0]          with cost 0.40 (path-cost so far: 0.25)\n",
      "  From [0]          to [0 1]          with cost 0.60 (path-cost so far: 0.36)\n",
      "  From [1]          to [1 0]          with cost 0.42 (path-cost so far: 0.16)\n",
      "  From [1]          to [1 1]          with cost 0.58 (path-cost so far: 0.23)\n",
      "  From [0 1]        to [0 1 0]        with cost 0.15 (path-cost so far: 0.05)\n",
      "  From [0 1]        to [0 1 1]        with cost 0.85 (path-cost so far: 0.31)\n",
      "  From [0 1 1]      to [0 1 1 0]      with cost 0.78 (path-cost so far: 0.24)\n",
      "  From [0 1 1]      to [0 1 1 1]      with cost 0.22 (path-cost so far: 0.07)\n",
      "  From [0 0]        to [0 0 0]        with cost 0.33 (path-cost so far: 0.08)\n",
      "  From [0 0]        to [0 0 1]        with cost 0.67 (path-cost so far: 0.16)\n",
      "  From [0 1 1 0]    to [0 1 1 0 0]    with cost 0.99 (path-cost so far: 0.24)\n",
      "  From [0 1 1 0]    to [0 1 1 0 1]    with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [0 1 1 0 0]  to [0 1 1 0 0 0]  with cost 1.00 (path-cost so far: 0.24)\n",
      "  From [0 1 1 0 0]  to [0 1 1 0 0 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1]        to [1 1 0]        with cost 0.64 (path-cost so far: 0.15)\n",
      "  From [1 1]        to [1 1 1]        with cost 0.36 (path-cost so far: 0.08)\n",
      "  From [0 0 1]      to [0 0 1 0]      with cost 0.40 (path-cost so far: 0.06)\n",
      "  From [0 0 1]      to [0 0 1 1]      with cost 0.60 (path-cost so far: 0.10)\n",
      "  From [1 0]        to [1 0 0]        with cost 0.84 (path-cost so far: 0.14)\n",
      "  From [1 0]        to [1 0 1]        with cost 0.16 (path-cost so far: 0.03)\n",
      "  From [1 1 0]      to [1 1 0 0]      with cost 0.98 (path-cost so far: 0.14)\n",
      "  From [1 1 0]      to [1 1 0 1]      with cost 0.02 (path-cost so far: 0.00)\n",
      "  From [1 1 0 0]    to [1 1 0 0 0]    with cost 1.00 (path-cost so far: 0.14)\n",
      "  From [1 1 0 0]    to [1 1 0 0 1]    with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 0 0 0]  to [1 1 0 0 0 0]  with cost 0.96 (path-cost so far: 0.14)\n",
      "  From [1 1 0 0 0]  to [1 1 0 0 0 1]  with cost 0.04 (path-cost so far: 0.01)\n",
      "  From [1 0 0]      to [1 0 0 0]      with cost 0.92 (path-cost so far: 0.13)\n",
      "  From [1 0 0]      to [1 0 0 1]      with cost 0.08 (path-cost so far: 0.01)\n",
      "  From [1 0 0 0]    to [1 0 0 0 0]    with cost 0.94 (path-cost so far: 0.12)\n",
      "  From [1 0 0 0]    to [1 0 0 0 1]    with cost 0.06 (path-cost so far: 0.01)\n",
      "  From [1 0 0 0 0]  to [1 0 0 0 0 0]  with cost 0.54 (path-cost so far: 0.06)\n",
      "  From [1 0 0 0 0]  to [1 0 0 0 0 1]  with cost 0.46 (path-cost so far: 0.05)\n",
      "  From [0 0 1 1]    to [0 0 1 1 0]    with cost 0.58 (path-cost so far: 0.06)\n",
      "  From [0 0 1 1]    to [0 0 1 1 1]    with cost 0.42 (path-cost so far: 0.04)\n",
      "  From [0 0 0]      to [0 0 0 0]      with cost 0.59 (path-cost so far: 0.05)\n",
      "  From [0 0 0]      to [0 0 0 1]      with cost 0.41 (path-cost so far: 0.03)\n",
      "  From [1 1 1]      to [1 1 1 0]      with cost 0.97 (path-cost so far: 0.08)\n",
      "  From [1 1 1]      to [1 1 1 1]      with cost 0.03 (path-cost so far: 0.00)\n",
      "  From [1 1 1 0]    to [1 1 1 0 0]    with cost 1.00 (path-cost so far: 0.08)\n",
      "  From [1 1 1 0]    to [1 1 1 0 1]    with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 1 0 0]  to [1 1 1 0 0 0]  with cost 1.00 (path-cost so far: 0.08)\n",
      "  From [1 1 1 0 0]  to [1 1 1 0 0 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [0 1 1 1]    to [0 1 1 1 0]    with cost 0.96 (path-cost so far: 0.06)\n",
      "  From [0 1 1 1]    to [0 1 1 1 1]    with cost 0.04 (path-cost so far: 0.00)\n",
      "  From [0 0 1 0]    to [0 0 1 0 0]    with cost 0.80 (path-cost so far: 0.05)\n",
      "  From [0 0 1 0]    to [0 0 1 0 1]    with cost 0.20 (path-cost so far: 0.01)\n",
      "  From [0 1 1 1 0]  to [0 1 1 1 0 0]  with cost 1.00 (path-cost so far: 0.06)\n",
      "  From [0 1 1 1 0]  to [0 1 1 1 0 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [0 0 1 1 0]  to [0 0 1 1 0 0]  with cost 0.99 (path-cost so far: 0.06)\n",
      "  From [0 0 1 1 0]  to [0 0 1 1 0 1]  with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [0 1 0]      to [0 1 0 0]      with cost 0.89 (path-cost so far: 0.05)\n",
      "  From [0 1 0]      to [0 1 0 1]      with cost 0.11 (path-cost so far: 0.01)\n",
      "  From [0 0 1 0 0]  to [0 0 1 0 0 0]  with cost 0.94 (path-cost so far: 0.05)\n",
      "  From [0 0 1 0 0]  to [0 0 1 0 0 1]  with cost 0.06 (path-cost so far: 0.00)\n",
      "  From [0 0 0 0]    to [0 0 0 0 0]    with cost 0.79 (path-cost so far: 0.04)\n",
      "  From [0 0 0 0]    to [0 0 0 0 1]    with cost 0.21 (path-cost so far: 0.01)\n",
      "  From [0 1 0 0]    to [0 1 0 0 0]    with cost 0.99 (path-cost so far: 0.05)\n",
      "  From [0 1 0 0]    to [0 1 0 0 1]    with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [0 1 0 0 0]  to [0 1 0 0 0 0]  with cost 0.92 (path-cost so far: 0.04)\n",
      "  From [0 1 0 0 0]  to [0 1 0 0 0 1]  with cost 0.08 (path-cost so far: 0.00)\n",
      "  From [0 0 1 1 1]  to [0 0 1 1 1 0]  with cost 1.00 (path-cost so far: 0.04)\n",
      "  From [0 0 1 1 1]  to [0 0 1 1 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [0 0 0 0 0]  to [0 0 0 0 0 0]  with cost 0.37 (path-cost so far: 0.01)\n",
      "  From [0 0 0 0 0]  to [0 0 0 0 0 1]  with cost 0.63 (path-cost so far: 0.02)\n",
      "  From [0 0 0 1]    to [0 0 0 1 0]    with cost 0.56 (path-cost so far: 0.02)\n",
      "  From [0 0 0 1]    to [0 0 0 1 1]    with cost 0.44 (path-cost so far: 0.01)\n",
      "  From [1 0 1]      to [1 0 1 0]      with cost 0.84 (path-cost so far: 0.02)\n",
      "  From [1 0 1]      to [1 0 1 1]      with cost 0.16 (path-cost so far: 0.00)\n",
      "  From [1 0 1 0]    to [1 0 1 0 0]    with cost 0.94 (path-cost so far: 0.02)\n",
      "  From [1 0 1 0]    to [1 0 1 0 1]    with cost 0.06 (path-cost so far: 0.00)\n",
      "  From [1 0 1 0 0]  to [1 0 1 0 0 0]  with cost 0.97 (path-cost so far: 0.02)\n",
      "  From [1 0 1 0 0]  to [1 0 1 0 0 1]  with cost 0.03 (path-cost so far: 0.00)\n",
      "  From [0 0 0 1 0]  to [0 0 0 1 0 0]  with cost 0.78 (path-cost so far: 0.01)\n",
      "  From [0 0 0 1 0]  to [0 0 0 1 0 1]  with cost 0.22 (path-cost so far: 0.00)\n",
      "  From [0 0 0 1 1]  to [0 0 0 1 1 0]  with cost 0.93 (path-cost so far: 0.01)\n",
      "  From [0 0 0 1 1]  to [0 0 0 1 1 1]  with cost 0.07 (path-cost so far: 0.00)\n",
      "  From [0 0 1 0 1]  to [0 0 1 0 1 0]  with cost 0.98 (path-cost so far: 0.01)\n",
      "  From [0 0 1 0 1]  to [0 0 1 0 1 1]  with cost 0.02 (path-cost so far: 0.00)\n",
      "  From [1 0 0 1]    to [1 0 0 1 0]    with cost 0.84 (path-cost so far: 0.01)\n",
      "  From [1 0 0 1]    to [1 0 0 1 1]    with cost 0.16 (path-cost so far: 0.00)\n",
      "  From [0 0 0 0 1]  to [0 0 0 0 1 0]  with cost 0.69 (path-cost so far: 0.01)\n",
      "  From [0 0 0 0 1]  to [0 0 0 0 1 1]  with cost 0.31 (path-cost so far: 0.00)\n",
      "  From [1 0 0 1 0]  to [1 0 0 1 0 0]  with cost 0.87 (path-cost so far: 0.01)\n",
      "  From [1 0 0 1 0]  to [1 0 0 1 0 1]  with cost 0.13 (path-cost so far: 0.00)\n",
      "  From [1 0 0 0 1]  to [1 0 0 0 1 0]  with cost 0.81 (path-cost so far: 0.01)\n",
      "  From [1 0 0 0 1]  to [1 0 0 0 1 1]  with cost 0.19 (path-cost so far: 0.00)\n",
      "  From [0 1 0 1]    to [0 1 0 1 0]    with cost 0.96 (path-cost so far: 0.01)\n",
      "  From [0 1 0 1]    to [0 1 0 1 1]    with cost 0.04 (path-cost so far: 0.00)\n",
      "  From [0 1 0 1 0]  to [0 1 0 1 0 0]  with cost 0.99 (path-cost so far: 0.01)\n",
      "  From [0 1 0 1 0]  to [0 1 0 1 0 1]  with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [1 0 1 1]    to [1 0 1 1 0]    with cost 0.85 (path-cost so far: 0.00)\n",
      "  From [1 0 1 1]    to [1 0 1 1 1]    with cost 0.15 (path-cost so far: 0.00)\n",
      "  From [1 0 1 1 0]  to [1 0 1 1 0 0]  with cost 0.99 (path-cost so far: 0.00)\n",
      "  From [1 0 1 1 0]  to [1 0 1 1 0 1]  with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [0 1 1 0 1]  to [0 1 1 0 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [0 1 1 0 1]  to [0 1 1 0 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 1 1]    to [1 1 1 1 0]    with cost 0.99 (path-cost so far: 0.00)\n",
      "  From [1 1 1 1]    to [1 1 1 1 1]    with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [1 1 1 1 0]  to [1 1 1 1 0 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [1 1 1 1 0]  to [1 1 1 1 0 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [0 1 1 1 1]  to [0 1 1 1 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [0 1 1 1 1]  to [0 1 1 1 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 0 1]    to [1 1 0 1 0]    with cost 0.99 (path-cost so far: 0.00)\n",
      "  From [1 1 0 1]    to [1 1 0 1 1]    with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [1 1 0 1 0]  to [1 1 0 1 0 0]  with cost 0.99 (path-cost so far: 0.00)\n",
      "  From [1 1 0 1 0]  to [1 1 0 1 0 1]  with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [1 0 0 1 1]  to [1 0 0 1 1 0]  with cost 0.96 (path-cost so far: 0.00)\n",
      "  From [1 0 0 1 1]  to [1 0 0 1 1 1]  with cost 0.04 (path-cost so far: 0.00)\n",
      "  From [1 0 1 0 1]  to [1 0 1 0 1 0]  with cost 0.99 (path-cost so far: 0.00)\n",
      "  From [1 0 1 0 1]  to [1 0 1 0 1 1]  with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [0 1 0 0 1]  to [0 1 0 0 1 0]  with cost 0.98 (path-cost so far: 0.00)\n",
      "  From [0 1 0 0 1]  to [0 1 0 0 1 1]  with cost 0.02 (path-cost so far: 0.00)\n",
      "  From [1 0 1 1 1]  to [1 0 1 1 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [1 0 1 1 1]  to [1 0 1 1 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 0 0 1]  to [1 1 0 0 1 0]  with cost 0.99 (path-cost so far: 0.00)\n",
      "  From [1 1 0 0 1]  to [1 1 0 0 1 1]  with cost 0.01 (path-cost so far: 0.00)\n",
      "  From [1 1 1 0 1]  to [1 1 1 0 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [1 1 1 0 1]  to [1 1 1 0 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [0 1 0 1 1]  to [0 1 0 1 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [0 1 0 1 1]  to [0 1 0 1 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 1 1 1]  to [1 1 1 1 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [1 1 1 1 1]  to [1 1 1 1 1 1]  with cost 0.00 (path-cost so far: 0.00)\n",
      "  From [1 1 0 1 1]  to [1 1 0 1 1 0]  with cost 1.00 (path-cost so far: 0.00)\n",
      "  From [1 1 0 1 1]  to [1 1 0 1 1 1]  with cost 0.00 (path-cost so far: 0.00)\n"
     ]
    }
   ],
   "source": [
    "# For a particular example, we get \n",
    "# * paths: the paths explored \n",
    "# * y_argmax: the most likely path \n",
    "# * y_max: the value of the most likely path\n",
    "print(\"\\nBranches:\")\n",
    "branches,y_argmax,y_max = cc.explore_paths(X_test[0],epsilon=eps)\n",
    "# Print the branches\n",
    "for (y_parent,y_child,prob_branch,prob_path) in branches:\n",
    "    print(\"  From {:12s} to {:14s} with cost {:3.2f} (path-cost so far: {:3.2f})\".format(str(y_parent),str(y_child),prob_branch,prob_path))\n",
    "\n",
    "# Save the paths to a file in in a format that we can draw easily later\n",
    "print_ptree(branches,\"probability_tree_exploration.dot\",y_best=y_argmax.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
